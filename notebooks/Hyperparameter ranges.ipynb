{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from piex import explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "piex = explorer.PipelineExplorer('ml-pipelines-2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = piex.get_pipelines(data_modality='single_table', task_type='classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best(k):\n",
    "    def f(gdf):\n",
    "        return gdf.sort_values('rank').iloc[0:k]\n",
    "    \n",
    "    return f\n",
    "    \n",
    "bdf = df.groupby('dataset').apply(get_best(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2340, 11)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>data_modality</th>\n",
       "      <th>dataset</th>\n",
       "      <th>metric</th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>task_type</th>\n",
       "      <th>template</th>\n",
       "      <th>test_id</th>\n",
       "      <th>pipeline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1491_one_hundred_plants_dataset_TRAIN</th>\n",
       "      <th>1815222</th>\n",
       "      <td>febd5b88-435f-440f-bb44-d7c114a3ce07</td>\n",
       "      <td>single_table</td>\n",
       "      <td>1491_one_hundred_plants_dataset_TRAIN</td>\n",
       "      <td>f1Macro</td>\n",
       "      <td>dfs/categorical_encoder/imputer/standard_scale...</td>\n",
       "      <td>0.220910</td>\n",
       "      <td>0.779090</td>\n",
       "      <td>classification</td>\n",
       "      <td>5bd106fb49e71569e8bf8071</td>\n",
       "      <td>20181025043231171172</td>\n",
       "      <td>dfs/categorical_encoder/imputer/standard_scale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510781</th>\n",
       "      <td>f9aa8d58-3307-4f54-8569-871d4a02c9c6</td>\n",
       "      <td>single_table</td>\n",
       "      <td>1491_one_hundred_plants_dataset_TRAIN</td>\n",
       "      <td>f1Macro</td>\n",
       "      <td>categorical_encoder/imputer/standard_scaler/ra...</td>\n",
       "      <td>0.258131</td>\n",
       "      <td>0.741869</td>\n",
       "      <td>classification</td>\n",
       "      <td>5bd106fb49e71569e8bf806f</td>\n",
       "      <td>20181025042919337776</td>\n",
       "      <td>categorical_encoder/imputer/standard_scaler/ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684953</th>\n",
       "      <td>3f8be58d-aef5-4d9d-9dc3-9a4e3906eb1b</td>\n",
       "      <td>single_table</td>\n",
       "      <td>1491_one_hundred_plants_dataset_TRAIN</td>\n",
       "      <td>f1Macro</td>\n",
       "      <td>categorical_encoder/imputer/standard_scaler/ra...</td>\n",
       "      <td>0.263567</td>\n",
       "      <td>0.736433</td>\n",
       "      <td>classification</td>\n",
       "      <td>5bd106fb49e71569e8bf806f</td>\n",
       "      <td>20181025042919337776</td>\n",
       "      <td>categorical_encoder/imputer/standard_scaler/ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673272</th>\n",
       "      <td>50148c3a-3eb4-4846-8e20-83dd9ef2e776</td>\n",
       "      <td>single_table</td>\n",
       "      <td>1491_one_hundred_plants_dataset_TRAIN</td>\n",
       "      <td>f1Macro</td>\n",
       "      <td>categorical_encoder/imputer/standard_scaler/ra...</td>\n",
       "      <td>0.268612</td>\n",
       "      <td>0.731388</td>\n",
       "      <td>classification</td>\n",
       "      <td>5bd106fb49e71569e8bf806f</td>\n",
       "      <td>20181025042919337776</td>\n",
       "      <td>categorical_encoder/imputer/standard_scaler/ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794742</th>\n",
       "      <td>f576467c-8f08-4cbc-ac3e-a0e609c09b5a</td>\n",
       "      <td>single_table</td>\n",
       "      <td>1491_one_hundred_plants_dataset_TRAIN</td>\n",
       "      <td>f1Macro</td>\n",
       "      <td>dfs/categorical_encoder/imputer/standard_scale...</td>\n",
       "      <td>0.290822</td>\n",
       "      <td>0.709178</td>\n",
       "      <td>classification</td>\n",
       "      <td>5bd106fb49e71569e8bf8071</td>\n",
       "      <td>20181025043231171172</td>\n",
       "      <td>dfs/categorical_encoder/imputer/standard_scale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                _id  \\\n",
       "dataset                                                                               \n",
       "1491_one_hundred_plants_dataset_TRAIN 1815222  febd5b88-435f-440f-bb44-d7c114a3ce07   \n",
       "                                      1510781  f9aa8d58-3307-4f54-8569-871d4a02c9c6   \n",
       "                                      1684953  3f8be58d-aef5-4d9d-9dc3-9a4e3906eb1b   \n",
       "                                      1673272  50148c3a-3eb4-4846-8e20-83dd9ef2e776   \n",
       "                                      1794742  f576467c-8f08-4cbc-ac3e-a0e609c09b5a   \n",
       "\n",
       "                                              data_modality  \\\n",
       "dataset                                                       \n",
       "1491_one_hundred_plants_dataset_TRAIN 1815222  single_table   \n",
       "                                      1510781  single_table   \n",
       "                                      1684953  single_table   \n",
       "                                      1673272  single_table   \n",
       "                                      1794742  single_table   \n",
       "\n",
       "                                                                             dataset  \\\n",
       "dataset                                                                                \n",
       "1491_one_hundred_plants_dataset_TRAIN 1815222  1491_one_hundred_plants_dataset_TRAIN   \n",
       "                                      1510781  1491_one_hundred_plants_dataset_TRAIN   \n",
       "                                      1684953  1491_one_hundred_plants_dataset_TRAIN   \n",
       "                                      1673272  1491_one_hundred_plants_dataset_TRAIN   \n",
       "                                      1794742  1491_one_hundred_plants_dataset_TRAIN   \n",
       "\n",
       "                                                metric  \\\n",
       "dataset                                                  \n",
       "1491_one_hundred_plants_dataset_TRAIN 1815222  f1Macro   \n",
       "                                      1510781  f1Macro   \n",
       "                                      1684953  f1Macro   \n",
       "                                      1673272  f1Macro   \n",
       "                                      1794742  f1Macro   \n",
       "\n",
       "                                                                                            name  \\\n",
       "dataset                                                                                            \n",
       "1491_one_hundred_plants_dataset_TRAIN 1815222  dfs/categorical_encoder/imputer/standard_scale...   \n",
       "                                      1510781  categorical_encoder/imputer/standard_scaler/ra...   \n",
       "                                      1684953  categorical_encoder/imputer/standard_scaler/ra...   \n",
       "                                      1673272  categorical_encoder/imputer/standard_scaler/ra...   \n",
       "                                      1794742  dfs/categorical_encoder/imputer/standard_scale...   \n",
       "\n",
       "                                                   rank     score  \\\n",
       "dataset                                                             \n",
       "1491_one_hundred_plants_dataset_TRAIN 1815222  0.220910  0.779090   \n",
       "                                      1510781  0.258131  0.741869   \n",
       "                                      1684953  0.263567  0.736433   \n",
       "                                      1673272  0.268612  0.731388   \n",
       "                                      1794742  0.290822  0.709178   \n",
       "\n",
       "                                                    task_type  \\\n",
       "dataset                                                         \n",
       "1491_one_hundred_plants_dataset_TRAIN 1815222  classification   \n",
       "                                      1510781  classification   \n",
       "                                      1684953  classification   \n",
       "                                      1673272  classification   \n",
       "                                      1794742  classification   \n",
       "\n",
       "                                                               template  \\\n",
       "dataset                                                                   \n",
       "1491_one_hundred_plants_dataset_TRAIN 1815222  5bd106fb49e71569e8bf8071   \n",
       "                                      1510781  5bd106fb49e71569e8bf806f   \n",
       "                                      1684953  5bd106fb49e71569e8bf806f   \n",
       "                                      1673272  5bd106fb49e71569e8bf806f   \n",
       "                                      1794742  5bd106fb49e71569e8bf8071   \n",
       "\n",
       "                                                            test_id  \\\n",
       "dataset                                                               \n",
       "1491_one_hundred_plants_dataset_TRAIN 1815222  20181025043231171172   \n",
       "                                      1510781  20181025042919337776   \n",
       "                                      1684953  20181025042919337776   \n",
       "                                      1673272  20181025042919337776   \n",
       "                                      1794742  20181025043231171172   \n",
       "\n",
       "                                                                                        pipeline  \n",
       "dataset                                                                                           \n",
       "1491_one_hundred_plants_dataset_TRAIN 1815222  dfs/categorical_encoder/imputer/standard_scale...  \n",
       "                                      1510781  categorical_encoder/imputer/standard_scaler/ra...  \n",
       "                                      1684953  categorical_encoder/imputer/standard_scaler/ra...  \n",
       "                                      1673272  categorical_encoder/imputer/standard_scaler/ra...  \n",
       "                                      1794742  dfs/categorical_encoder/imputer/standard_scale...  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"Progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  33%|███▎      | 778/2340 [06:27<12:56,  2.01it/s]"
     ]
    }
   ],
   "source": [
    "best_pipelines = bdf['_id'].progress_apply(lambda i: piex.get_json('pipelines', i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2340"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = best_pipelines.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpdf = pd.DataFrame(list(best_pipelines.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hyperparameters(pdf):\n",
    "    pdf = pdf.copy()\n",
    "    hyperparameters = dict()\n",
    "    for primitive, hp in pdf.pop('hyperparameters').items():\n",
    "        for key, value in hp.items():\n",
    "            hyperparameters[primitive + '#' + key] = value\n",
    "\n",
    "    hyperparameters['hyperparameter_names'] = list(hyperparameters.keys())\n",
    "    hyperparameters['template'] = pdf['template']\n",
    "    return pd.Series(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpdf = bpdf.apply(extract_hyperparameters, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>featuretools.dfs#1#encode</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>featuretools.dfs#1#max_depth</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>featuretools.dfs#1#remove_low_information</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyperparameter_names</th>\n",
       "      <td>[featuretools.dfs#1#encode, featuretools.dfs#1...</td>\n",
       "      <td>[featuretools.dfs#1#encode, featuretools.dfs#1...</td>\n",
       "      <td>[mlprimitives.feature_extraction.CategoricalEn...</td>\n",
       "      <td>[mlprimitives.feature_extraction.CategoricalEn...</td>\n",
       "      <td>[featuretools.dfs#1#encode, featuretools.dfs#1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlprimitives.feature_extraction.CategoricalEncoder#1#copy</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlprimitives.feature_extraction.CategoricalEncoder#1#features</th>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlprimitives.feature_extraction.CategoricalEncoder#1#max_labels</th>\n",
       "      <td>83</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.ensemble.RandomForestClassifier#1#class_weight</th>\n",
       "      <td>balanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.ensemble.RandomForestClassifier#1#criterion</th>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.ensemble.RandomForestClassifier#1#max_depth</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.ensemble.RandomForestClassifier#1#max_features</th>\n",
       "      <td>log2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.ensemble.RandomForestClassifier#1#min_samples_leaf</th>\n",
       "      <td>0.00633427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0079643</td>\n",
       "      <td>0.00726345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.ensemble.RandomForestClassifier#1#min_samples_split</th>\n",
       "      <td>0.0204164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0497636</td>\n",
       "      <td>0.0239512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.ensemble.RandomForestClassifier#1#n_estimators</th>\n",
       "      <td>449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.ensemble.RandomForestClassifier#1#n_jobs</th>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.preprocessing.Imputer#1#axis</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.preprocessing.Imputer#1#copy</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.preprocessing.Imputer#1#missing_values</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.preprocessing.Imputer#1#strategy</th>\n",
       "      <td>median</td>\n",
       "      <td>most_frequent</td>\n",
       "      <td>median</td>\n",
       "      <td>mean</td>\n",
       "      <td>most_frequent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.preprocessing.StandardScaler#1#with_mean</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sklearn.preprocessing.StandardScaler#1#with_std</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>template</th>\n",
       "      <td>5bd106fb49e71569e8bf8071</td>\n",
       "      <td>5bd106fb49e71569e8bf806d</td>\n",
       "      <td>5bd0ce5249e71569e8bf8003</td>\n",
       "      <td>5bd106fb49e71569e8bf806f</td>\n",
       "      <td>5bd106fb49e71569e8bf8071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost.XGBClassifier#1#gamma</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.599703</td>\n",
       "      <td>0.0573631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost.XGBClassifier#1#learning_rate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533626</td>\n",
       "      <td>0.428396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost.XGBClassifier#1#max_depth</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost.XGBClassifier#1#min_child_weight</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost.XGBClassifier#1#n_estimators</th>\n",
       "      <td>NaN</td>\n",
       "      <td>932</td>\n",
       "      <td>615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgboost.XGBClassifier#1#n_jobs</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    0  \\\n",
       "featuretools.dfs#1#encode                                                                        True   \n",
       "featuretools.dfs#1#max_depth                                                                        1   \n",
       "featuretools.dfs#1#remove_low_information                                                        True   \n",
       "hyperparameter_names                                [featuretools.dfs#1#encode, featuretools.dfs#1...   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                               True   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                               auto   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                                 83   \n",
       "sklearn.ensemble.RandomForestClassifier#1#class...                                           balanced   \n",
       "sklearn.ensemble.RandomForestClassifier#1#crite...                                            entropy   \n",
       "sklearn.ensemble.RandomForestClassifier#1#max_d...                                                 14   \n",
       "sklearn.ensemble.RandomForestClassifier#1#max_f...                                               log2   \n",
       "sklearn.ensemble.RandomForestClassifier#1#min_s...                                         0.00633427   \n",
       "sklearn.ensemble.RandomForestClassifier#1#min_s...                                          0.0204164   \n",
       "sklearn.ensemble.RandomForestClassifier#1#n_est...                                                449   \n",
       "sklearn.ensemble.RandomForestClassifier#1#n_jobs                                                   -1   \n",
       "sklearn.preprocessing.Imputer#1#axis                                                                0   \n",
       "sklearn.preprocessing.Imputer#1#copy                                                             True   \n",
       "sklearn.preprocessing.Imputer#1#missing_values                                                    NaN   \n",
       "sklearn.preprocessing.Imputer#1#strategy                                                       median   \n",
       "sklearn.preprocessing.StandardScaler#1#with_mean                                                False   \n",
       "sklearn.preprocessing.StandardScaler#1#with_std                                                  True   \n",
       "template                                                                     5bd106fb49e71569e8bf8071   \n",
       "xgboost.XGBClassifier#1#gamma                                                                     NaN   \n",
       "xgboost.XGBClassifier#1#learning_rate                                                             NaN   \n",
       "xgboost.XGBClassifier#1#max_depth                                                                 NaN   \n",
       "xgboost.XGBClassifier#1#min_child_weight                                                          NaN   \n",
       "xgboost.XGBClassifier#1#n_estimators                                                              NaN   \n",
       "xgboost.XGBClassifier#1#n_jobs                                                                    NaN   \n",
       "\n",
       "                                                                                                    1  \\\n",
       "featuretools.dfs#1#encode                                                                        True   \n",
       "featuretools.dfs#1#max_depth                                                                        1   \n",
       "featuretools.dfs#1#remove_low_information                                                        True   \n",
       "hyperparameter_names                                [featuretools.dfs#1#encode, featuretools.dfs#1...   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                               True   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                               auto   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                                 48   \n",
       "sklearn.ensemble.RandomForestClassifier#1#class...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#crite...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#max_d...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#max_f...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#min_s...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#min_s...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#n_est...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#n_jobs                                                  NaN   \n",
       "sklearn.preprocessing.Imputer#1#axis                                                                0   \n",
       "sklearn.preprocessing.Imputer#1#copy                                                             True   \n",
       "sklearn.preprocessing.Imputer#1#missing_values                                                    NaN   \n",
       "sklearn.preprocessing.Imputer#1#strategy                                                most_frequent   \n",
       "sklearn.preprocessing.StandardScaler#1#with_mean                                                False   \n",
       "sklearn.preprocessing.StandardScaler#1#with_std                                                 False   \n",
       "template                                                                     5bd106fb49e71569e8bf806d   \n",
       "xgboost.XGBClassifier#1#gamma                                                                0.599703   \n",
       "xgboost.XGBClassifier#1#learning_rate                                                        0.533626   \n",
       "xgboost.XGBClassifier#1#max_depth                                                                   5   \n",
       "xgboost.XGBClassifier#1#min_child_weight                                                            6   \n",
       "xgboost.XGBClassifier#1#n_estimators                                                              932   \n",
       "xgboost.XGBClassifier#1#n_jobs                                                                     -1   \n",
       "\n",
       "                                                                                                    2  \\\n",
       "featuretools.dfs#1#encode                                                                         NaN   \n",
       "featuretools.dfs#1#max_depth                                                                      NaN   \n",
       "featuretools.dfs#1#remove_low_information                                                         NaN   \n",
       "hyperparameter_names                                [mlprimitives.feature_extraction.CategoricalEn...   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                               True   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                               auto   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                                 26   \n",
       "sklearn.ensemble.RandomForestClassifier#1#class...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#crite...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#max_d...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#max_f...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#min_s...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#min_s...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#n_est...                                                NaN   \n",
       "sklearn.ensemble.RandomForestClassifier#1#n_jobs                                                  NaN   \n",
       "sklearn.preprocessing.Imputer#1#axis                                                                0   \n",
       "sklearn.preprocessing.Imputer#1#copy                                                             True   \n",
       "sklearn.preprocessing.Imputer#1#missing_values                                                    NaN   \n",
       "sklearn.preprocessing.Imputer#1#strategy                                                       median   \n",
       "sklearn.preprocessing.StandardScaler#1#with_mean                                                 True   \n",
       "sklearn.preprocessing.StandardScaler#1#with_std                                                  True   \n",
       "template                                                                     5bd0ce5249e71569e8bf8003   \n",
       "xgboost.XGBClassifier#1#gamma                                                               0.0573631   \n",
       "xgboost.XGBClassifier#1#learning_rate                                                        0.428396   \n",
       "xgboost.XGBClassifier#1#max_depth                                                                  10   \n",
       "xgboost.XGBClassifier#1#min_child_weight                                                            9   \n",
       "xgboost.XGBClassifier#1#n_estimators                                                              615   \n",
       "xgboost.XGBClassifier#1#n_jobs                                                                     -1   \n",
       "\n",
       "                                                                                                    3  \\\n",
       "featuretools.dfs#1#encode                                                                         NaN   \n",
       "featuretools.dfs#1#max_depth                                                                      NaN   \n",
       "featuretools.dfs#1#remove_low_information                                                         NaN   \n",
       "hyperparameter_names                                [mlprimitives.feature_extraction.CategoricalEn...   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                               True   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                               auto   \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                                 24   \n",
       "sklearn.ensemble.RandomForestClassifier#1#class...                                           balanced   \n",
       "sklearn.ensemble.RandomForestClassifier#1#crite...                                            entropy   \n",
       "sklearn.ensemble.RandomForestClassifier#1#max_d...                                                 23   \n",
       "sklearn.ensemble.RandomForestClassifier#1#max_f...                                               None   \n",
       "sklearn.ensemble.RandomForestClassifier#1#min_s...                                          0.0079643   \n",
       "sklearn.ensemble.RandomForestClassifier#1#min_s...                                          0.0497636   \n",
       "sklearn.ensemble.RandomForestClassifier#1#n_est...                                                 69   \n",
       "sklearn.ensemble.RandomForestClassifier#1#n_jobs                                                   -1   \n",
       "sklearn.preprocessing.Imputer#1#axis                                                                0   \n",
       "sklearn.preprocessing.Imputer#1#copy                                                             True   \n",
       "sklearn.preprocessing.Imputer#1#missing_values                                                    NaN   \n",
       "sklearn.preprocessing.Imputer#1#strategy                                                         mean   \n",
       "sklearn.preprocessing.StandardScaler#1#with_mean                                                 True   \n",
       "sklearn.preprocessing.StandardScaler#1#with_std                                                  True   \n",
       "template                                                                     5bd106fb49e71569e8bf806f   \n",
       "xgboost.XGBClassifier#1#gamma                                                                     NaN   \n",
       "xgboost.XGBClassifier#1#learning_rate                                                             NaN   \n",
       "xgboost.XGBClassifier#1#max_depth                                                                 NaN   \n",
       "xgboost.XGBClassifier#1#min_child_weight                                                          NaN   \n",
       "xgboost.XGBClassifier#1#n_estimators                                                              NaN   \n",
       "xgboost.XGBClassifier#1#n_jobs                                                                    NaN   \n",
       "\n",
       "                                                                                                    4  \n",
       "featuretools.dfs#1#encode                                                                        True  \n",
       "featuretools.dfs#1#max_depth                                                                        2  \n",
       "featuretools.dfs#1#remove_low_information                                                       False  \n",
       "hyperparameter_names                                [featuretools.dfs#1#encode, featuretools.dfs#1...  \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                               True  \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                               auto  \n",
       "mlprimitives.feature_extraction.CategoricalEnco...                                                 65  \n",
       "sklearn.ensemble.RandomForestClassifier#1#class...                                           balanced  \n",
       "sklearn.ensemble.RandomForestClassifier#1#crite...                                            entropy  \n",
       "sklearn.ensemble.RandomForestClassifier#1#max_d...                                                 26  \n",
       "sklearn.ensemble.RandomForestClassifier#1#max_f...                                               auto  \n",
       "sklearn.ensemble.RandomForestClassifier#1#min_s...                                         0.00726345  \n",
       "sklearn.ensemble.RandomForestClassifier#1#min_s...                                          0.0239512  \n",
       "sklearn.ensemble.RandomForestClassifier#1#n_est...                                                380  \n",
       "sklearn.ensemble.RandomForestClassifier#1#n_jobs                                                   -1  \n",
       "sklearn.preprocessing.Imputer#1#axis                                                                0  \n",
       "sklearn.preprocessing.Imputer#1#copy                                                             True  \n",
       "sklearn.preprocessing.Imputer#1#missing_values                                                    NaN  \n",
       "sklearn.preprocessing.Imputer#1#strategy                                                most_frequent  \n",
       "sklearn.preprocessing.StandardScaler#1#with_mean                                                 True  \n",
       "sklearn.preprocessing.StandardScaler#1#with_std                                                  True  \n",
       "template                                                                     5bd106fb49e71569e8bf8071  \n",
       "xgboost.XGBClassifier#1#gamma                                                                     NaN  \n",
       "xgboost.XGBClassifier#1#learning_rate                                                             NaN  \n",
       "xgboost.XGBClassifier#1#max_depth                                                                 NaN  \n",
       "xgboost.XGBClassifier#1#min_child_weight                                                          NaN  \n",
       "xgboost.XGBClassifier#1#n_estimators                                                              NaN  \n",
       "xgboost.XGBClassifier#1#n_jobs                                                                    NaN  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpdf.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_template(hpdf, bpdf, template_id):\n",
    "    hpdf = hpdf[hpdf.template == template_id]\n",
    "    pipeline = bpdf[bpdf['template'] == template_id].iloc[0]\n",
    "    \n",
    "    init_parameters = pipeline['init_params']\n",
    "    hyperparameters = dict()\n",
    "    for primitive, parameter in pipeline['tunable_hyperparameters'].items():\n",
    "        primitive_init_parameters = init_parameters.get(primitive, dict())\n",
    "        primitive_hyperparameters = dict()\n",
    "        hyperparameters[primitive] = primitive_hyperparameters\n",
    "        \n",
    "        for name, spec in parameter.items():\n",
    "            key = primitive + '#' + name\n",
    "            param_type = spec['type']\n",
    "\n",
    "            if len(hpdf[key].unique()) == 1:\n",
    "                primitive_init_params[name] = hpdf[key].mode()[0]\n",
    "                \n",
    "            elif param_type in ('bool', 'str'):\n",
    "                hyperparameter = {\n",
    "                    'type': param_type,\n",
    "                    'default': hpdf[key].mode()[0]\n",
    "                }\n",
    "                if param_type != 'bool':\n",
    "                    hyperparameter['values'] = list(hpdf[key].unique())\n",
    "\n",
    "                primitive_hyperparameters[name] = hyperparameter\n",
    "                    \n",
    "            elif param_type == 'float':\n",
    "                std = hpdf[key].std()\n",
    "                primitive_hyperparameters[name] = {\n",
    "                    'type': param_type,\n",
    "                    'range': [\n",
    "                        max(hpdf[key].min() - std, spec['range'][0]),\n",
    "                        min(hpdf[key].max() + std, spec['range'][1])\n",
    "                    ],\n",
    "                    'default': hpdf[key].mean()\n",
    "                }\n",
    "                \n",
    "            elif param_type == 'int':\n",
    "                primitive_hyperparameters[name] = {\n",
    "                    'type': param_type,\n",
    "                    'range': [hpdf[key].min(), hpdf[key].max()],\n",
    "                    'default': int(hpdf[key].mean())\n",
    "                }\n",
    "\n",
    "            \n",
    "    metadata = pipeline['loader']\n",
    "    metadata['name'] = pipeline['name']\n",
    "    return {\n",
    "        'metadata': metadata,\n",
    "        'init_params': init_parameters,\n",
    "        'input_name': pipeline['input_names'],\n",
    "        'output_name': pipeline['output_names'],\n",
    "        'primitives': pipeline['primitives'],\n",
    "        'tunable_hyperparameters': hyperparameters\n",
    "    }\n",
    "\n",
    "template = build_template(hpdf, bpdf, '5bd106fb49e71569e8bf8071')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def within_ranges(pipeline, template):\n",
    "    pipeline_hyperparameters = pipeline['hyperparameters']\n",
    "    template_init_params = template['init_params']\n",
    "    for primitive, tunables in template['tunable_hyperparameters'].items():\n",
    "        init_params = template_init_params.get(primitive, dict())\n",
    "        for name, value in pipeline_hyperparameters[primitive].items():\n",
    "            tunable = tunables.get(name)\n",
    "            if tunable:\n",
    "                tunable_type = tunable['type']\n",
    "                if tunable_type == 'str' and value not in tunable['values']:\n",
    "                    return False\n",
    "                \n",
    "                elif tunable_type in ('int', 'float'):\n",
    "                    tunable_range = tunable['range']\n",
    "                    if not (tunable_range[0] <= value <= tunable_range[1]):\n",
    "                        return False\n",
    "                    \n",
    "            elif name in init_params:\n",
    "                if init_params[name] != value:\n",
    "                    return False\n",
    "\n",
    "    return True\n",
    "\n",
    "pipeline = best_pipelines[0]\n",
    "template = build_template(hpdf, bpdf, pipeline['template'])\n",
    "within_ranges(pipeline, template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_datasets(df):\n",
    "    datasets = pd.Series(df.dataset.unique())\n",
    "    datasets = datasets.sample(len(datasets))\n",
    "    half = int(len(datasets) / 2)\n",
    "\n",
    "    first_half = df[df.dataset.isin(datasets[:half])]\n",
    "    second_half = df[df.dataset.isin(datasets[half:])]\n",
    "\n",
    "    return first_half, second_half\n",
    "\n",
    "bpdf_1, bpdf_2 = split_datasets(bpdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1170, 17), (1170, 17))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpdf_1.shape, bpdf_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpdf_1 = bpdf_1.apply(extract_hyperparameters, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpdf_2 = bpdf_2.apply(extract_hyperparameters, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1170, 28), (1170, 28))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpdf_1.shape, hpdf_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_ids = hpdf_1.template.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = dict()\n",
    "for template_id in template_ids:\n",
    "    templates[template_id] = build_template(hpdf_1, bpdf_1, template_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(template_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pipelines_within_ranges(pipelines):\n",
    "    within = list()\n",
    "    for pipeline in pipelines.to_dict(orient='records'):\n",
    "        is_within = within_ranges(\n",
    "            pipeline,\n",
    "            templates[pipeline['template']]\n",
    "        )\n",
    "        within.append(is_within)\n",
    "    \n",
    "    return np.array(within)\n",
    "\n",
    "def within_ranges_ratio(pipelines):\n",
    "    return pipelines_within_ranges(pipelines).mean()\n",
    "\n",
    "def any_within_ranges(pipelines):\n",
    "    return pipelines_within_ranges(pipelines).any()\n",
    "\n",
    "def all_within_ranges(pipelines):\n",
    "    return pipelines_within_ranges(pipelines).all()\n",
    "\n",
    "def best_within_ranges(pipelines):\n",
    "    best = pipelines.sort_values('rank').iloc[0]\n",
    "    return within_ranges(best, templates[best['template']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_stats = {\n",
    "    'any_within': bpdf_2.groupby('dataset').apply(any_within_ranges),\n",
    "    'all_within': bpdf_2.groupby('dataset').apply(all_within_ranges),\n",
    "    'within_ratio': bpdf_2.groupby('dataset').apply(within_ranges_ratio),\n",
    "    'best_within': bpdf_2.groupby('dataset').apply(best_within_ranges),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf = pd.DataFrame(within_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>any_within</th>\n",
       "      <th>all_within</th>\n",
       "      <th>within_ratio</th>\n",
       "      <th>best_within</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185_baseball_dataset_TRAIN</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27_ws_dataset_TRAIN</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313_spectrometer_dataset_TRAIN</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38_sick_dataset_TRAIN</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57_hd_dataset_TRAIN</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                any_within  all_within  within_ratio  \\\n",
       "dataset                                                                \n",
       "185_baseball_dataset_TRAIN            True        True           1.0   \n",
       "27_ws_dataset_TRAIN                   True        True           1.0   \n",
       "313_spectrometer_dataset_TRAIN        True        True           1.0   \n",
       "38_sick_dataset_TRAIN                 True        True           1.0   \n",
       "57_hd_dataset_TRAIN                   True        True           1.0   \n",
       "\n",
       "                                best_within  \n",
       "dataset                                      \n",
       "185_baseball_dataset_TRAIN             True  \n",
       "27_ws_dataset_TRAIN                    True  \n",
       "313_spectrometer_dataset_TRAIN         True  \n",
       "38_sick_dataset_TRAIN                  True  \n",
       "57_hd_dataset_TRAIN                    True  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "any_within      1.000000\n",
       "all_within      0.905983\n",
       "within_ratio    0.988889\n",
       "best_within     0.974359\n",
       "dtype: float64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdf.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
